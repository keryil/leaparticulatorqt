{
 "metadata": {
  "name": "",
  "signature": "sha256:d613d2659c9e96566dbb6e8167c77bb92e0d0f4c523e13acc2051cd3bcf47e9f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile AnalyzeOnCluster.py\n",
      "import timeit, traceback\n",
      "from datetime import datetime\n",
      "from StreamlinedDataAnalysis import *\n",
      "\n",
      "import subprocess, time\n",
      "def start_cluster(working_dir):\n",
      "    p = subprocess.Popen(\"ipcluster start\".split(), stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
      "                         cwd=working_dir)\n",
      "    time.sleep(5)\n",
      "    p.stdout.readline()\n",
      "    return not (\"Cluster is already running\" in p.stdout.readline())\n",
      "\n",
      "def stop_cluster(working_dir):\n",
      "    magic = \"a\"\n",
      "    while \"probably not running\" not in magic:\n",
      "        p = subprocess.Popen(\"ipcluster stop\".split(), stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
      "                             cwd=working_dir)\n",
      "        time.sleep(4)\n",
      "        p.stdout.readline()\n",
      "        magic = p.stdout.readline()\n",
      "        print magic\n",
      "\n",
      "def analyze_by_cluster(files, working_dir, fargs, restart_cluster=True):\n",
      "    nstates, trials, iter, units = fargs\n",
      "#     log_name = (\"logs/automated_%s.log\" % datetime.now()).replace(\" \", \"_\")\n",
      "    # %logstart log_name\n",
      "    # %logon\n",
      "    # files = files[16:]\n",
      "    # files = ['1320149514.2']\n",
      "    for i, f in enumerate(files):\n",
      "    #     with open((\"automated_%s.log\" % datetime.now()).replace(\" \", \"_\"), \"w\") as log:\n",
      "    #         write = lambda x: log.write(x + \"\\n\")\n",
      "            if restart_cluster:\n",
      "                while not start_cluster(working_dir):\n",
      "                    print_n_flush(\"Cluster already running; trying to restart...\")\n",
      "        #             write(\"Cluster already running; trying to restart...\")\n",
      "                    stop_cluster(working_dir)\n",
      "                    print_n_flush(\"Stopped the old cluster, hopefully...\")\n",
      "        #             write(\"Stopped the old cluster, hopefully...\")\n",
      "\n",
      "                print_n_flush(\"Successfully started the new cluster.\")\n",
      "            else:\n",
      "                start_cluster()\n",
      "    #         write(\"Successfully started the new cluster.\")\n",
      "#             success = False\n",
      "#             while not success:\n",
      "            print f\n",
      "        #     if f != \"132r01921514.2r\":\n",
      "        #         continue\n",
      "        #     else:\n",
      "            print_n_flush(\"----->Starting analysis of %s (%d out of %d)\" % (f, i+1, len(files)))\n",
      "#             write(\"----->Starting analysis of %s (%d out of %d)\" % (f, i+1, len(files)))    \n",
      "            start = timeit.default_timer()\n",
      "#                 try:\n",
      "            analyze_log_file_in_phases_by_condition(f, nstates=nstates, trials=trials, iter=iter, \n",
      "                                                    units=units, parallel=True)\n",
      "\n",
      "            stop = timeit.default_timer()\n",
      "            print_n_flush(\"Analysis of %s done (%f seconds)\" % (f, stop-start))\n",
      "#                 write(\"Analysis of %s done (%f seconds)\" % (f, stop-start))\n",
      "                \n",
      "    #         break\n",
      "if __name__ == \"__main__\":\n",
      "    import sys\n",
      "#     print \"Cluster args received: %s\" % sys.argv\n",
      "    f, working_dir, trials, iter, units = sys.argv[1:6]\n",
      "    nstates = map(int, sys.argv[6:])\n",
      "    identifying_str = \\\n",
      "        \"\"\"\n",
      "        ***********\n",
      "        Cluster arguments\n",
      "        \n",
      "        Log file: %s\n",
      "        Working directory: %s\n",
      "        Number of states: %d..%d\n",
      "        Number of trials: %d\n",
      "        Number of iterations: %d\n",
      "        Measurement to fit to model: %s\n",
      "        ***********\n",
      "        \"\"\" % (f, working_dir, int(nstates[0]), int(nstates[-1]), int(trials), int(iter), units)\n",
      "    print_n_flush(identifying_str)\n",
      "    analyze_by_cluster([f], working_dir=working_dir, fargs=(nstates, int(trials), int(iter), units))\n",
      "    stop_cluster(working_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting AnalyzeOnCluster.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# %%script ipython\n",
      "import Constants\n",
      "import subprocess, sys, time\n",
      "from glob import glob\n",
      "import timeit\n",
      "working_dir = !pwd\n",
      "working_dir = str(working_dir[0])\n",
      "print working_dir\n",
      "# from AnalyzeOnCluster import analyze_by_cluster\n",
      "\n",
      "\n",
      "files = glob(\"logs/*.*.exp.log\")\n",
      "# print files[0]\n",
      "blacklist = [\"123R0126514.1r\"]\n",
      "path_to_cond = lambda x: x[:-8].split(\".\")[-1] \n",
      "file_to_id = lambda x: x.split('/')[-1][:-8]\n",
      "\n",
      "# only files with condition codings\n",
      "files = filter(lambda x: path_to_cond(x) in ('master','1','1r','2','2r'), files)\n",
      "files = map(file_to_id, files)\n",
      "\n",
      "# only files not blacklisted\n",
      "files = filter(lambda x: x not in blacklist, files)\n",
      "\n",
      "# only files with valid participant ids\n",
      "files = filter(lambda x: x[0] == '1', files)\n",
      " \n",
      "nstates = range(2,31)\n",
      "trials = 1\n",
      "iterations = 1000\n",
      "units = Constants.AMP_AND_MEL\n",
      "# files.index(\"13202126514.2\")\n",
      "# files = [\"123R0126514.1r\"]\n",
      "print files\n",
      "for i, f in enumerate(files):\n",
      "    print \"\\n***********\\nSending %s to the cluster, file %d of %d.\\n***********\\n\" % (f, i+1, len(files))\n",
      "    nstates = \" \".join(map(str, nstates))\n",
      "    command = \"python AnalyzeOnCluster.py %s %s %s %s %s %s\" % (f, working_dir, trials, iterations, units, nstates)\n",
      "    process = subprocess.Popen(command.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
      "    print \"Started new process with PID %d\" % process.pid\n",
      "    sys.stdout.flush()\n",
      "    done = False\n",
      "    while not done:\n",
      "        out = process.stdout.readline()\n",
      "        err = process.stderr.readline()\n",
      "        printed = False\n",
      "        if (\"Analysis of %s done\" % f) in out:\n",
      "#             print \"A-HA!\"\n",
      "            done = True\n",
      "        if out != '':\n",
      "            print out.rstrip()\n",
      "            sys.stdout.flush()\n",
      "            printed = True\n",
      "        if err != '':\n",
      "            print err.rstrip()\n",
      "            sys.stdout.flush()\n",
      "            printed = True\n",
      "        if not printed:\n",
      "            time.sleep(20)\n",
      "    process.terminate()\n",
      "    process.wait()\n",
      "    print \"Process %s returned with code %s\" % (process.pid, process.returncode)\n",
      "# analyze_by_cluster(files[2:], working_dir=working_dir, fargs=(nstates, trials, iter, Constants.AMP_AND_MEL))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/shared/Dropbox/ABACUS/Workspace/LeapArticulator\n",
        "['1230105514.master', '12301720514.1', '123r01619514.1r', '1320116514.2', '1320149514.2', '123R0147514.1r', '13201820514.2', '13202021514.2', '132R0139514.2r', '132r01513514.2r', '1230115514.master', '123r01821514.1r', '123R0223614.1r', '13201516514.2', '13202126514.2', '132r01619514.2r', '12301921514.1', '12301516514.1', '123R0137514.1r', '13201720514.2', '132R0128514.2r', '132r01921514.2r']\n",
        "\n",
        "***********\n",
        "Sending 1230105514.master to the cluster, file 1 of 22.\n",
        "***********\n",
        "\n",
        "Started new process with PID 12678\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}