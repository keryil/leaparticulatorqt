{
 "metadata": {
  "name": "",
  "signature": "sha256:4582d2a3d87f5335c0c8d00ac5ff096e43565646727634eb4e6930868f62c210"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Import data and output to file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ExperimentalData import fromFile, toCSV, HMM\n",
      "import pandas as pd\n",
      "import jsonpickle\n",
      "import numpy as np\n",
      "import sys\n",
      "\n",
      "colors = [(x/10.,y/20.,z/40.) for x, y, z in zip(range(10), range(10), range(10))]\n",
      "colors.extend([(x/40.,y/20.,z/10.) for x, y, z in zip(range(1,10), range(1,10), range(1,10))])\n",
      "colors.extend([(x/40.,y/10.,z/20.) for x, y, z in zip(range(1,10), range(1,10), range(1,10))])\n",
      "colors.extend(['red','green','yellow', 'magenta', 'orange', 'black', 'cyan', 'white'])\n",
      "\n",
      "def print_n_flush(*args):\n",
      "#     from __future__ import print_function\n",
      "    print_on_single_line = False\n",
      "    for arg in args:\n",
      "        if \"\\n\" in arg:\n",
      "            if print_on_single_line:\n",
      "                print \"\\n\"\n",
      "                print_on_single_line = False\n",
      "            for aa in arg.split(\"\\n\"):\n",
      "                print aa\n",
      "        else:\n",
      "            print arg,\n",
      "            print_on_single_line = True\n",
      "    if print_on_single_line:\n",
      "        print \"\\n\"\n",
      "    sys.stdout.flush()\n",
      "    \n",
      "pd.set_option(\"display.max_columns\", None)\n",
      "file_id = \"1230105514.master\"\n",
      "id_to_log = lambda x: \"logs/%s.exp.log\" % x\n",
      "# filename_log = id_to_log(file_id)\n",
      "# responses, tests, responses_t, tests_t, images = toCSV(filename_log)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# quiver_annotations = []\n",
      "from trajectory import Trajectory\n",
      "def plot_quiver2d(data, alpha=.75, C=[], path=None, *args, **kwargs):\n",
      "    global quiver_annotations\n",
      "    \n",
      "    X, Y = zip(*tuple(data))\n",
      "    U = [x1-x0 for x0,x1 in zip(X[:-1],X[1:])]\n",
      "    V = [y1-y0 for y0,y1 in zip(Y[:-1],Y[1:])]\n",
      "    if C == []:\n",
      "        color_delta = 1. / (len(X) - 1)\n",
      "        C = [(color_delta*i,color_delta*i,color_delta*i) for i in range(len(X)-1)]\n",
      "#     print C\n",
      "    X, Y = X[:-1], Y[:-1]\n",
      "#     print X, Y, U, V\n",
      "    patches = quiver(X, Y, U, V, C, *args, scale_units='xy',angles='xy', scale=1, width=0.005, alpha=alpha, **kwargs)\n",
      "    return patches    \n",
      "    \n",
      "def find_bounding_box(trajectories):\n",
      "    xmin = ymin = 1000\n",
      "    xmax = ymax = -1000\n",
      "    delta = 1\n",
      "    for signal in trajectories:\n",
      "        for frame in signal:\n",
      "            x, y, z = frame.get_stabilized_position()\n",
      "            xmax = max(x + delta, xmax)\n",
      "            xmin = min(x - delta, xmin)\n",
      "            ymax = max(y + delta, ymax)\n",
      "            ymin = min(y - delta, ymin)\n",
      "    return xmin, xmax, ymin, ymax\n",
      "\n",
      "def to_trajectory_object(trajectory, xmin, ymin, xmax, ymax, step_size=10):\n",
      "    arr = [frame.get_stabilized_position()[:2] for frame in trajectory]\n",
      "    t = Trajectory(from_arr=arr, duration=len(arr), step_size=step_size, origin=(xmin, ymin), \n",
      "                   ndim=2, dim_size=(xmax-xmin, ymax-ymin), prob_c=1)\n",
      "    return t\n",
      "\n",
      "def to_trajectory_file(trajectories, filename):\n",
      "    xmin, xmax, ymin, ymax = find_bounding_box(trajectories)\n",
      "    start = 0\n",
      "    end = 1\n",
      "    import os\n",
      "    if os.path.isfile(filename):\n",
      "        os.remove(filename)\n",
      "    with open(filename, \"w\") as f:\n",
      "        print(xmin, xmax, ymin, ymax, start,end)\n",
      "        f.write(\"%d %d %d %d %d %d\\n\" % (xmin, xmax, ymin, ymax, start,end))\n",
      "        for signal in trajectories:\n",
      "            for frame in signal:\n",
      "                x, y, z = frame.get_stabilized_position()\n",
      "                time = frame.timestamp\n",
      "                f.write(\"%f %f %f\\n\" % (x, y, time))\n",
      "            f.write(\"0.0 0.0 0.0\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# r = responses[\"127.0.0.1\"]\n",
      "# r = r['1']\n",
      "# r = {\"1\":r}\n",
      "def responses_to_trajectories(responses):\n",
      "    counter = 0\n",
      "    trajectories = []\n",
      "    for host in responses:\n",
      "        r = responses[host]\n",
      "        for phase in r:\n",
      "            for image in r[phase]:\n",
      "        #         if image == u'./img/meanings/5_1.png':\n",
      "                    counter+=1\n",
      "                    trajectory = r[phase][image]\n",
      "                    trajectories.append(trajectory)\n",
      "                    data = []\n",
      "                    for frame in trajectory[:-1]:\n",
      "                        x, y, z = frame.get_stabilized_position()\n",
      "                        data.append((x,y))\n",
      "        #                 print frame.timestamp\n",
      "        #             plot_quiver2d(data)\n",
      "        #             break\n",
      "        #             plot(X,Y,label=\"%s-%s\" % (phase, image))\n",
      "    return trajectories"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plotting HMMs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_cov_ellipse(cov, pos, nstd=2, ax=None, **kwargs):\n",
      "    \"\"\"\n",
      "    Plots an `nstd` sigma error ellipse based on the specified covariance\n",
      "    matrix (`cov`). Additional keyword arguments are passed on to the \n",
      "    ellipse patch artist.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "        cov : The 2x2 covariance matrix to base the ellipse on\n",
      "        pos : The location of the center of the ellipse. Expects a 2-element\n",
      "            sequence of [x0, y0].\n",
      "        nstd : The radius of the ellipse in numbers of standard deviations.\n",
      "            Defaults to 2 standard deviations.\n",
      "        ax : The axis that the ellipse will be plotted on. Defaults to the \n",
      "            current axis.\n",
      "        Additional keyword arguments are pass on to the ellipse patch.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "        A matplotlib ellipse artist\n",
      "    \"\"\"\n",
      "    from matplotlib.pyplot import gca\n",
      "    def eigsorted(cov):\n",
      "        vals, vecs = np.linalg.eigh(cov)\n",
      "        order = vals.argsort()[::-1]\n",
      "        return vals[order], vecs[:,order]\n",
      "\n",
      "    if ax is None:\n",
      "        ax = gca()\n",
      "\n",
      "    vals, vecs = eigsorted(cov)\n",
      "    theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
      "\n",
      "    # Width and height are \"full\" widths, not radius\n",
      "    width, height = 2 * nstd * np.sqrt(vals)\n",
      "    ellip = Ellipse(xy=pos, width=width, height=height, angle=theta, **kwargs)\n",
      "\n",
      "    ax.add_artist(ellip)\n",
      "    return ellip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib.colors import colorConverter\n",
      "from matplotlib.patches import Ellipse\n",
      "from matplotlib.pyplot import scatter, annotate, quiver, legend, gca, gcf\n",
      "from numpy import log\n",
      "# figure()\n",
      "# means = []\n",
      "# annotations = []\n",
      "\n",
      "def on_pick(event):\n",
      "    print event\n",
      "    print annotations\n",
      "    if event.artist in annotations:\n",
      "        on_pick_annotation(event)\n",
      "    elif event.artist in means:\n",
      "        on_pick_means(event)\n",
      "    draw()\n",
      "    time.sleep(1)\n",
      "\n",
      "def on_pick_trajectory_event(event):\n",
      "    pass\n",
      "    \n",
      "def on_pick_annotation(event):\n",
      "    print \"Annotation:\", event.artist\n",
      "    event.artist.set_visible(False)\n",
      "\n",
      "def on_pick_means(event):\n",
      "    print \"Mean:\", means.index(event.artist)\n",
      "    annotations[means.index(event.artist)].set_visible(True)\n",
      "    print annotations[means.index(event.artist)]\n",
      "\n",
      "# colors = ['red','green','yellow', 'magenta', 'orange', 'black', 'cyan', 'white']\n",
      "def plot_hmm(means_, transmat, covars, initProbs, axes=None):\n",
      "    if axes != None:\n",
      "        axes(axes)\n",
      "#     f, axes = subplots(2)#,sharex=True, sharey=True)\n",
      "#     sca(axes[0])\n",
      "    global annotations\n",
      "    annotations = []\n",
      "    global means\n",
      "    means = []\n",
      "    color_map = colors #[colorConverter.to_rgb(colors[i]) for i in range(len(means_))]\n",
      "    for i, mean in enumerate(means_):\n",
      "#         print \"MEAN:\", tuple(mean)\n",
      "        means.append(scatter(*tuple(mean), color=colorConverter.to_rgb(colors[i]), picker=10, label=\"State%i\"%i))\n",
      "        annotate(s=\"%d\" % i, xy=mean, xytext=(-10,-10), xycoords=\"data\",textcoords=\"offset points\", \n",
      "                         alpha=1,bbox=dict(boxstyle='round,pad=0.2', fc=colorConverter.to_rgb(colors[i]), alpha=0.3))\n",
      "#         gca().add_patch(Ellipse(xy = means_[i], width = np.diag(covars[i])[0], height = np.diag(covars[i])[1],\n",
      "#                         alpha=.15, color=colorConverter.to_rgb(colors[i])))\n",
      "        plot_cov_ellipse(covars[i], mean, alpha=.15, color=colorConverter.to_rgb(colors[i]))\n",
      "        x0, y0 = mean\n",
      "        prob_string = \"P(t0)=%f\" % initProbs[i]\n",
      "        for j, p in enumerate(transmat[i]):\n",
      "            xdif = 10\n",
      "            ydif = 5\n",
      "            s = \"P(%d->%d)=%f\" % (i,j,p)\n",
      "#             print \"State%d: %s\" % (i, s)\n",
      "            prob_string = \"%s\\n%s\" % (prob_string,s)\n",
      "            if i != j:\n",
      "                x1, y1 = means_[j]\n",
      "                # if transmat[i][j] is too low, we get an underflow here\n",
      "#                 q = quiver([x0], [y0], [x1-x0], [y1-y0], alpha = 10000 * (transmat[i][j]**2),\n",
      "                alpha = 10 ** -300\n",
      "                if p > 10 ** -100:\n",
      "                    alpha = (100 * p)**2\n",
      "                q = quiver([x0], [y0], [x1-x0], [y1-y0], alpha = 1 / log(alpha), \n",
      "                       scale_units='xy',angles='xy', scale=1, width=0.005, label=\"P(%d->%d)=%f\" % (i,j,p))\n",
      "        legend()\n",
      "\n",
      "        annotations.append(annotate(s=prob_string, xy=mean, xytext=(0, 10), xycoords=\"data\",textcoords=\"offset points\", \n",
      "                         alpha=1,bbox=dict(boxstyle='round,pad=0.2', fc=colorConverter.to_rgb(colors[i]), alpha=0.3), picker=True,\n",
      "                         visible=False))\n",
      "\n",
      "\n",
      "        print \"State%i is %s\" % (i, colors[i])\n",
      "    cid = gcf().canvas.mpl_connect('pick_event', on_pick)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_hmm_path(trajectory_objs, paths, legends=[], items=[]):\n",
      "    global colors\n",
      "    print \"Colors are:\", colors\n",
      "    for i, (trajectory, p) in enumerate(zip(trajectory_objs, paths)): \n",
      "        print \"Path:\", p\n",
      "        tr_colors = [colors[int(state)] for state in p]\n",
      "        t = trajectory.plot2d(color=tr_colors)\n",
      "    #     t = plot_quiver2d(trajectory, color=tr_colors, path=p)\n",
      "        too_high = [tt for tt in trajectory if tt[1] > 400]\n",
      "#         print \"Too high\", too_high\n",
      "        legends.append(\"Trajectory%i\" % i)\n",
      "    #     items.append(p)\n",
      "        items.append(t)\n",
      "    #gca().legend()\n",
      "\n",
      "\n",
      "\n",
      "    # Let's create checkboxes\n",
      "    rax = plt.axes([0.05, 0.4, 0.1, 0.15])\n",
      "    # rax = plt.gca()\n",
      "    from matplotlib.widgets import CheckButtons\n",
      "    check = CheckButtons(rax, legends, [True] * len(legends))\n",
      "    # plt.sca(axes)\n",
      "\n",
      "    def func(label):\n",
      "        widget = items[legends.index(label)]\n",
      "        widget.set_visible(not widget.get_visible())\n",
      "        plt.draw()\n",
      "\n",
      "    check.on_clicked(func)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Now for R"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note:** The cell below includes functions to train multiple HMMs using the same parameters, and to pick the one with the lowest BIC. Because Baum-Welch algorithm is an EM algorithm, so it is easy to get stuck at local optima if only a few runs are made.\n",
      "\n",
      "I tried to integrate this into ipcluster but for some reason source(blabla) doesn't work as expected, and even when it does, the returned HMM vector is a SexpVector instead of the expected ListVector."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from IPython.parallel import Client\n",
      "# from functools import partial\n",
      "# from rpy2.rinterface import initr\n",
      "# initr()\n",
      "# client = Client(profile=\"default\")\n",
      "# # client[:].push(dict(initr=initr))\n",
      "# # client[:].apply_sync(lambda: initr())\n",
      "# lview = client.load_balanced_view() # default load-balanced view\n",
      "# lview.block = True\n",
      "import Constants\n",
      "def train_hmm_once(file_id, nstates, iter=1000, phase=2, cond=None, units=Constants.XY):\n",
      "    \"\"\"\n",
      "    Trains a Gaussian HMM using the data from an experimental log file, \n",
      "    using the specified number of states. When condition is unspecified,\n",
      "    we assume condition 1. \n",
      "    \"\"\"\n",
      "    from IPython.parallel import CompositeError\n",
      "    from rpy2.rinterface import RRuntimeError\n",
      "    cond_text = None\n",
      "    phase = int(phase)\n",
      "    x, y = None, None\n",
      "    if units == Constants.AMP_AND_FREQ:\n",
      "        x, y = \"frequency\", \"amplitude\"\n",
      "    elif units == Constants.AMP_AND_MEL:\n",
      "        x, y = \"mel\", \"amplitude\"\n",
      "    elif units == Constants.XY:\n",
      "        x, y = \"x\", \"y\"\n",
      "    print \"Units: %s, x: %s, y: %s\" % (units, x, y)\n",
      "    cond_text = \"c('%s','%s')\" % (x,y)\n",
      "    if cond == \"master\":\n",
      "        cond = \"1\"\n",
      "    if cond is None:\n",
      "        pass\n",
      "    elif phase == 0:\n",
      "        if \"r\" not in cond:\n",
      "            cond_text = \"c('%s')\" % x\n",
      "        else:\n",
      "            cond_text = \"c('%s')\" % y\n",
      "    elif phase == 1:\n",
      "        if \"2\" in cond:\n",
      "            cond_text = cond_text\n",
      "        elif \"r\" in cond:\n",
      "            cond_text = \"c('%s')\" % y\n",
      "        else:\n",
      "            cond_text = \"c('%s')\" % x\n",
      "    elif phase == 2:\n",
      "        if \"1\" in cond:\n",
      "            cond_text == cond_text\n",
      "        elif \"r\" in cond:\n",
      "            cond_text = \"c('%s')\" % y\n",
      "        else:\n",
      "            cond_text = \"c('%s')\" % x\n",
      "    else:\n",
      "        raise Exception(\"Invalid phase %s\" %  phase)\n",
      "   \n",
      "#     from rpy2.rinterface import initr\n",
      "#     initr()\n",
      "#     %load_ext rpy2.ipython\n",
      "    from rpy2.robjects import r, globalenv\n",
      "    from rpy2 import robjects\n",
      "#     initr()\n",
      "    r(\"rm(list = setdiff(ls(), lsf.str()))\")\n",
      "    r(\"source(\\\"~/Dropbox/ABACUS/Workspace/LeapArticulator/SampleHMM.R\\\")\")\n",
      "#     %R source(\"~/Dropbox/ABACUS/Workspace/LeapArticulator/SampleHMM.R\")\n",
      "#     r('file_id = %s' % file_id)\n",
      "#     r('nstates = %s' % nstates)\n",
      "#     robjects.globalenv['file_id'] = file_id\n",
      "#     robjects.globalenv['nstates'] = nstates\n",
      "#     %Rpush file_id \n",
      "#     %Rpush nstates\n",
      "#     %R list[hmm, d] = fitHMM(file_id, nstates, iter=1000)\n",
      "#     %Rpull d\n",
      "#     %Rpull hmm\n",
      "    success = False\n",
      "    attempts = 1\n",
      "    while not success:\n",
      "        try:\n",
      "            if attempts > 5:\n",
      "                print_n_flush(\"Giving up after %d attempts\" % attempts)\n",
      "                break\n",
      "            command = \"list[hmm, d] <- fitHMMtoPhase(file_id='%s', nStates=%s, iter=%d, phase=%d, take_vars=%s);\" % (file_id, nstates, iter, \n",
      "                                                                                              phase, cond_text)\n",
      "            print_n_flush(\"R command (attempt %d): %s\" % (attempts, command))\n",
      "            attempts += 1\n",
      "            r(command)\n",
      "            hmm, d = globalenv['hmm'], globalenv['d']\n",
      "            converged = False\n",
      "            if hmm is not None:\n",
      "                converged = r(\"hmm$convergence\")\n",
      "        #     print \"Finished a %s state run\" % nstates\n",
      "        #     print \"BIC:\", hmm.rx(\"BIC\")[0][0]\n",
      "        #     print \"AIC:\", hmm.rx(\"AIC\")[0][0]\n",
      "        #     print \"Returning:\", (hmm,d)\n",
      "            if not converged:\n",
      "                print_n_flush(\"Returning a null hmm for nstates=%s, cond:ph=%s:%s, units=%s\" % (nstates, cond, phase, units))\n",
      "                hmm = None\n",
      "            return hmm, d\n",
      "        except RRuntimeError, e:\n",
      "            print_n_flush(\"RRuntimeError: %s\" % e)\n",
      "            continue\n",
      "    #                 write(\"RRuntimeError: %s\" % e)\n",
      "        except CompositeError, e:\n",
      "            print_n_flush(\"Composite error ******\")\n",
      "            print_n_flush(e)\n",
      "            continue\n",
      "    #                 write(\"Composite error ******\")\n",
      "    #                 write(e)\n",
      "    #             e.raise_exception()\n",
      "        except Exception, e:\n",
      "            import traceback\n",
      "            print_n_flush(\"Error during analysis: \")\n",
      "            print_n_flush(e, e.args)\n",
      "            print_n_flush(traceback.format_exc())\n",
      "            continue\n",
      "    #                 write(\"Error during analysis: \")\n",
      "    #                 write( e, e.args)\n",
      "    #                 write( traceback.format_exc())\n",
      "        except:\n",
      "            print_n_flush(\"Some other exception that is not an exception.\")\n",
      "            continue\n",
      "    #                 write(\"Some other exception that is not an exception.\")\n",
      "        success = True\n",
      "\n",
      "def train_hmm_n_times(file_id, nstates, trials=20, iter=1000, pickle=True, \n",
      "                      phase=2, cond=None, units=Constants.XY, parallel=True):\n",
      "    \"\"\"\n",
      "    Trains multiple HMM's (as many as trials parameter per nstate) and chooses the one with the \n",
      "    lowest BIC, so as to avoid local optima. units parameter can be \"xy\", \"amp_and_freq\", or\n",
      "    \"amp_and_mel\", which specifies the kind of data to fit the HMM to. \n",
      "    \"\"\"\n",
      "    def pick_lowest_bic(models):\n",
      "        hmm, d, bic = None, None, 9999999999\n",
      "        for a in models:\n",
      "#             print list(a)\n",
      "            if a is None:\n",
      "                continue\n",
      "            hmmm, dd = a\n",
      "            if hmmm is None:\n",
      "                continue\n",
      "            # use this for ipcluster cases\n",
      "            bbic = hmmm[2][0]\n",
      "            # use this for non-cluster cases\n",
      "            # bbic = hmmm.rx(\"BIC\")[0][0]\n",
      "            if bbic < bic:\n",
      "                bic = bbic\n",
      "                hmm = hmmm\n",
      "#                 print \"Type:\", type(dd)\n",
      "                d = [np.array(i) for i in dd]\n",
      "#                 np.asarray(d)\n",
      "                d = np.asarray(d)\n",
      "        if hmm is None:\n",
      "            return (None, d)\n",
      "        Hmm = HMM(hmm, training_data=d)\n",
      "#         print \"New hmm and data (%s)\" % d\n",
      "#         Hmm.from_R(hmm)\n",
      "        return (Hmm, d)\n",
      "    \n",
      "    from IPython.parallel import Client\n",
      "    client = Client(profile=\"default\")\n",
      "    # client[:].push(dict(initr=initr))\n",
      "    # client[:].apply_sync(lambda: initr())\n",
      "    lview = client.load_balanced_view() # default load-balanced view\n",
      "    \n",
      "    lview.block = True\n",
      "    hmm, d, bic = None, None, None\n",
      "    \n",
      "    def do_train_svp(args):\n",
      "        return train_hmm_once(file_id=args[0], nstates=args[1], iter=args[2], \n",
      "                              phase=args[3], cond=args[4], units=args[5])\n",
      "    \n",
      "    at_least_one_valid = False\n",
      "    counter = 0\n",
      "    while not at_least_one_valid:\n",
      "        counter += 1\n",
      "        my_map = lview.map\n",
      "        if not parallel:\n",
      "            my_map = map\n",
      "        results = []\n",
      "        args = []\n",
      "        lview.block = False\n",
      "        if len(nstates) != 1:\n",
      "            for nstate in nstates[:-1]:\n",
      "                args = [(file_id, nstate, iter, phase, cond, units)] * trials\n",
      "                rr = my_map(do_train_svp, args)\n",
      "                results.append(rr)\n",
      "    #             results.append(map(func, args))\n",
      "                print_n_flush(\"Submitted the %d state models (attempt #%d)\" % (nstate, counter))\n",
      "    #             print rr \n",
      "        lview.block = True\n",
      "        args = [(file_id, nstates[-1], iter, phase, cond, units)] * trials\n",
      "        results.append(my_map(do_train_svp,args))\n",
      "    #     results.append(map(func,args))\n",
      "\n",
      "        to_return = []\n",
      "        for nstates_r in results:\n",
      "            to_return.append(pick_lowest_bic(nstates_r))\n",
      "        for hmm, d in to_return:\n",
      "            if hmm is not None:\n",
      "#                 print hmm\n",
      "                at_least_one_valid = True\n",
      "                break\n",
      "        if counter == 3:\n",
      "            print_n_flush(\"Giving up after 3 tries, returning all-None HMMs.\")\n",
      "            with open(\"logs/%s.FAILURE\" % file_id, \"a\") as f:\n",
      "                from datetime import datetime\n",
      "                f.write(\"%s\\tPhase%d failed to produce any HMMs.\\n\" % (datetime.now(), phase))\n",
      "            at_least_one_valid = True\n",
      "            \n",
      "    if pickle is True:\n",
      "        pickle_results(to_return, nstates, trials, iter, id_to_log(file_id), phase, units=units)\n",
      "    return to_return\n",
      "        \n",
      "def pickle_results(results, nstates, trials, iter, filename_log, phase=None, units=Constants.XY):\n",
      "    import ExperimentalData\n",
      "    hmms, ds = zip(*results)\n",
      "    print hmms\n",
      "#     results_pickled = jsonpickle.encode((hmms, ds, nstates, trials, iter))\n",
      "    extension = \".hmms\"\n",
      "    if (phase is not None):\n",
      "        extension = \".phase%d.%s.hmms\" % (phase, units)\n",
      "    print_n_flush(\"Writing results to %s\" % (filename_log + extension))\n",
      "    with open(filename_log + extension, \"w\") as f:\n",
      "        for i, item in zip((\"hmms\", \"ds\", \"nstates\", \"trials\", \"iter\"),(hmms, ds, nstates, trials, iter)):\n",
      "#             print i\n",
      "#             if i == \"hmms\":\n",
      "#                 for a, hmm in enumerate(item):\n",
      "#                     print a, \"********\\n\", str(hmm)\n",
      "# #                     import pickle\n",
      "# #                     pickle.dumps(hmm)\n",
      "# #                     encoded = jsonpickle.encode(hmm)\n",
      "# #                     jsonpickle.decode(encoded)\n",
      "#                 f.write(jsonpickle.encode(item))\n",
      "#             else:\n",
      "#             print item\n",
      "            f.write(jsonpickle.encode(item))\n",
      "            f.write(\"\\n\")\n",
      "\n",
      "def unpickle_results(filename_log, phase=None, units=None):\n",
      "    import ExperimentalData\n",
      "    from collections import namedtuple\n",
      "    extension = \".hmms\"\n",
      "    hmms = ds = nstates = trials = iter = None\n",
      "    if phase is not None:\n",
      "        if units is not None:\n",
      "            extension = \".phase%d.%s.hmms\" % (phase, units)\n",
      "        # this clause is purely for backward compatibility with\n",
      "        # old pickle files\n",
      "        else:\n",
      "            extension = \".phase%d.hmms\" % (phase)\n",
      "    with open(filename_log + extension, \"r\") as f:\n",
      "        hmms =  jsonpickle.decode(f.readline().rstrip())\n",
      "        ds =  jsonpickle.decode(f.readline().rstrip())\n",
      "        nstates =  jsonpickle.decode(f.readline().rstrip())\n",
      "        trials =  jsonpickle.decode(f.readline().rstrip())\n",
      "        iter =  jsonpickle.decode(f.readline().rstrip())\n",
      "    Results = namedtuple(\"Results\", \"hmms ds nstates trials iterations\")\n",
      "    return Results(hmms, ds, nstates, trials, iter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def responses_to_traj_objs(responses, responses_t):\n",
      "    import trajectory\n",
      "    # reload(trajectory)\n",
      "    trajectories = responses_to_trajectories(responses)\n",
      "    trajectories_t = responses_to_trajectories(responses_t)\n",
      "    to_trajectory_file(trajectories, \"%s.trajectories\" % (\".\".join(filename_log.split(\".\")[:-2])))\n",
      "\n",
      "    all_trajectories = list(trajectories)\n",
      "    all_trajectories.extend(trajectories_t)\n",
      "    xmin, xmax, ymin, ymax = find_bounding_box(trajectories)\n",
      "    tr = [to_trajectory_object(trajectory, step_size=300, xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax) for trajectory in all_trajectories]\n",
      "    return tr, trajectories\n",
      "\n",
      "def pick_hmm_by_bic(hmms, responses, responses_t, plot=True):\n",
      "    responses_to_traj_objs(responses, responses_t)\n",
      "    states, bics, aics = [], [], []\n",
      "    best = 0\n",
      "    tr, trajectories = responses_to_traj_objs(responses, responses_t)\n",
      "    for i, (hmm, d) in enumerate(results):\n",
      "        if hmm is not None:\n",
      "    #         nstates = hmm[0][2][1][0]\n",
      "    #         bic = hmm[2][0]\n",
      "    #         aic = hmm[3][0]\n",
      "    #         nstates = hmm.rx(\"HMM\")[0].rx('distribution')[0].rx('nStates')[0]\n",
      "    #         bic = hmm.rx(\"BIC\")[0][0]\n",
      "    #         aic = hmm.rx(\"AIC\")[0][0]\n",
      "            states.append(hmm.nstates)\n",
      "            bics.append(hmm.bic)\n",
      "            if min(bics) == hmm.bic:\n",
      "                best = i\n",
      "            aics.append(hmm.aic)\n",
      "            #print aic, bic, nstates\n",
      "#     print states\n",
      "    n = sum(map(len, trajectories))\n",
      "    # n = len(trajectories)\n",
      "    # aicc = [aic + 2*k*(k+1)/(n-k-1) for aic, k in zip(aics, [s + s + s*s + s + s*2 for s in states])]\n",
      "    # plot nStates against BIC\n",
      "    if plot:\n",
      "        scatter(states, bics, label=\"BIC\", color=\"r\")\n",
      "        scatter(states, aics, label=\"AIC\", color='g')\n",
      "        # scatter(states, aicc, label=\"AICc\", color='b')\n",
      "        legend()\n",
      "    hmm, d = results[best]\n",
      "#     print best\n",
      "#     print aics\n",
      "    return hmm, d\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def analyze_log_file(file_id, nstates, trials, iter):\n",
      "    id_to_log = lambda x: \"logs/%s.exp.log\" % x\n",
      "    filename_log = id_to_log(file_id)\n",
      "    responses, tests, responses_t, tests_t, images = toCSV(filename_log)\n",
      "    \n",
      "    from IPython.parallel import Client\n",
      "#     from functools import partial\n",
      "    from rpy2.rinterface import initr\n",
      "    try:\n",
      "        rinterface.set_initoptions((\"--max-ppsize=500000\"))\n",
      "    except RuntimeError, e:\n",
      "        print \"Runtime error, probably redundant call to set_initoptions():\\n\\t\\t%s\" % e\n",
      "    initr()\n",
      "    client = Client(profile=\"default\")\n",
      "    # client[:].push(dict(initr=initr))\n",
      "    # client[:].apply_sync(lambda: initr())\n",
      "    lview = client.load_balanced_view() # default load-balanced view\n",
      "    lview.block = True\n",
      "    # func = lambda args: train_hmm_n_times(file_id=args[0], nstates=args[1], trials=args[2], iter=args[3])\n",
      "    # trials = 4\n",
      "    client[:].push(dict(train_hmm_once=train_hmm_once))\n",
      "    # args = [(file_id, nstates, trials, 1000) for nstates in range(5,10)]\n",
      "    # results = lview.map(func, args)# hmm, d, results = train_hmm_n_times(file_id, nstates, trials=20, iter=1000)\n",
      "    # pool.join()\n",
      "    results = train_hmm_n_times(file_id, nstates=nstates, trials=trials, iter=iter)\n",
      "    return results\n",
      "\n",
      "def analyze_log_file_in_phases(file_id, nstates, trials, iter):\n",
      "    print \"Starting phase by phase analysis...\"\n",
      "    id_to_log = lambda x: \"logs/%s.exp.log\" % x\n",
      "    filename_log = id_to_log(file_id)\n",
      "    responses, tests, responses_t, tests_t, images = toCSV(filename_log)\n",
      "    from IPython.parallel import Client\n",
      "#     from functools import partial\n",
      "    from rpy2.rinterface import initr\n",
      "    rinterface.set_initoptions((\"--max-ppsize=100000\"))\n",
      "    initr()\n",
      "    client = Client(profile=\"default\")\n",
      "    # client[:].push(dict(initr=initr))\n",
      "    # client[:].apply_sync(lambda: initr())\n",
      "    lview = client.load_balanced_view() # default load-balanced view\n",
      "    lview.block = True\n",
      "    # func = lambda args: train_hmm_n_times(file_id=args[0], nstates=args[1], trials=args[2], iter=args[3])\n",
      "    # trials = 4\n",
      "    client[:].push(dict(train_hmm_once=train_hmm_once))\n",
      "    # args = [(file_id, nstates, trials, 1000) for nstates in range(5,10)]\n",
      "    # results = lview.map(func, args)# hmm, d, results = train_hmm_n_times(file_id, nstates, trials=20, iter=1000)\n",
      "    # pool.join()\n",
      "    results = {}\n",
      "    for i in range(3):\n",
      "        results[i] = train_hmm_n_times(file_id, nstates=nstates, trials=trials, iter=iter, phase=i)\n",
      "    return results\n",
      "\n",
      "def analyze_log_file_in_phases_by_condition(file_id, nstates, trials, iter, units=Constants.XY, parallel=True):\n",
      "    print_n_flush(\"Starting phase by phase analysis, controlled for conditions (units: %s)...\" % units)\n",
      "    d = pd.read_csv(\"/shared/AudioData/ThereminData/surfacedata.csv\", na_values=[\"NaN\"])\n",
      "    \n",
      "    id_to_log = lambda x: \"logs/%s.exp.log\" % x\n",
      "    filename_log = id_to_log(file_id)\n",
      "    cond = file_id.split('.')[-1]\n",
      "    print_n_flush(\"Condition\", cond)\n",
      "    responses, tests, responses_t, tests_t, images = toCSV(filename_log)\n",
      "    from IPython.parallel import Client\n",
      "    import rpy2\n",
      "    from rpy2 import rinterface\n",
      "    try:\n",
      "        rinterface.set_initoptions((\"--max-ppsize=500000\",\"--vanilla\"))\n",
      "    except RuntimeError, e:\n",
      "        print \"Runtime error, probably redundant call to set_initoptions():\\n\\t\\t%s\" % e\n",
      "#         print e\n",
      "#     from functools import partial\n",
      "    from rpy2.rinterface import initr\n",
      "    initr()\n",
      "    client = Client(profile=\"default\")\n",
      "    # client[:].push(dict(initr=initr))\n",
      "    # client[:].apply_sync(lambda: initr())\n",
      "    lview = client.load_balanced_view() # default load-balanced view\n",
      "    lview.block = True\n",
      "    # func = lambda args: train_hmm_n_times(file_id=args[0], nstates=args[1], trials=args[2], iter=args[3])\n",
      "    # trials = 4\n",
      "    client[:].push(dict(train_hmm_once=train_hmm_once))\n",
      "    # args = [(file_id, nstates, trials, 1000) for nstates in range(5,10)]\n",
      "    # results = lview.map(func, args)# hmm, d, results = train_hmm_n_times(file_id, nstates, trials=20, iter=1000)\n",
      "    # pool.join()\n",
      "    results = {}\n",
      "    for i in range(3):\n",
      "        results[i] = train_hmm_n_times(file_id, nstates=nstates, trials=trials, iter=iter, phase=i, cond=cond,\n",
      "                                       units=units, parallel=parallel)\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pull_hmm_paths(d):\n",
      "    globalenv['d'] = d\n",
      "    r('library(\"RHmm\")')\n",
      "    r('path = list()')\n",
      "    r('for(trajectory in d){ path = c(path, viterbi(hmm, trajectory))}')\n",
      "    path = globalenv['path']\n",
      "    return path\n",
      "# from glob import glob\n",
      "# files = glob(\"logs/*.*.exp.log\")\n",
      "# files = [file for file in files if file[:-8].split(\".\")[-1] in ('master','1','1r','2','2r')]\n",
      "# print files, len(files)\n",
      "# for f in files:\n",
      "#     analyze_log_file_in_phases_by_condition(f[5:-8], 5, 1, 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "##%load_ext rpy2.ipython"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# getwd()\n",
      "# source('SampleHMM.R')\n",
      "# list[hmm, d] <- fitHMM(file_id = '123R0126514.1r', nStates = 6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# %Rpull hmm\n",
      "# hmm[1][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import rpy2.robjects.numpy2ri\n",
      "# from rpy2.robjects import r, globalenv\n",
      "\n",
      "# results = analyze_log_file(file_id, nstates = range(10,22), trials = 20, iter = 1000)\n",
      "# hmm, d = pick_hmm_by_bic(results, responses, responses_t, plot=False)\n",
      "\n",
      "# path = pull_hmm_paths(d)\n",
      "\n",
      "# paths = [numpy.asarray(path[i], dtype=int) for i in range(0, len(path), 3)]\n",
      "# tr, trajectories = responses_to_traj_objs(responses,responses_t)\n",
      "\n",
      "def draw():\n",
      "    means = hmm.means\n",
      "    transmat = hmm.transmat\n",
      "    initProb = hmm.initProb\n",
      "    covar = hmm.variances\n",
      "    nstates = hmm.nstates\n",
      "    x = zip(*means)[0]\n",
      "    y = zip(*means)[1]\n",
      "\n",
      "    legends = []\n",
      "    items = []\n",
      "    ax = None\n",
      "\n",
      "    plot_hmm(numpy.asarray(means), \n",
      "            numpy.asarray(transmat),\n",
      "            initProbs=numpy.asarray(initProb),\n",
      "            covars=covar, axes=ax)\n",
      "\n",
      "    plot_hmm_path(paths=paths, \n",
      "                  trajectory_objs=tr, \n",
      "                  legends=legends, \n",
      "                  items=items)\n",
      "    plt.draw()\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}