{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Kerem/Dropbox/ABACUS/Workspace/LeapArticulatorQt/leaparticulator/notebooks\n",
      "/Users/Kerem/Dropbox/ABACUS/Workspace/LeapArticulatorQt\n"
     ]
    }
   ],
   "source": [
    "# we are trying to add ../../ to the PYTHONPATH\n",
    "if 'set_path_' not in globals():\n",
    "    import os, sys\n",
    "    path = os.getcwd()\n",
    "    print path\n",
    "    path = path.split(os.path.sep)[:-2]\n",
    "    path = os.path.join(os.path.sep, *path)\n",
    "    if path.endswith(\"LeapArticulatorQt\"):\n",
    "        print path\n",
    "        sys.path.append(path)\n",
    "        global set_path_\n",
    "        set_path_ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import leaparticulator.data.functions as ExperimentalData\n",
    "from leaparticulator.data.functions import fromFile, toCSV\n",
    "from leaparticulator.data.hmm import HMM\n",
    "import pandas as pd\n",
    "import jsonpickle\n",
    "import numpy as np\n",
    "from leaparticulator import constants as Constants\n",
    "\n",
    "colors = [(x/10.,y/20.,z/40.) for x, y, z in zip(range(10), range(10), range(10))]\n",
    "colors.extend([(x/40.,y/20.,z/10.) for x, y, z in zip(range(1,10), range(1,10), range(1,10))])\n",
    "colors.extend([(x/40.,y/10.,z/20.) for x, y, z in zip(range(1,10), range(1,10), range(1,10))])\n",
    "# colors.extend(['red','green','yellow', 'magenta', 'orange', 'black', 'cyan', 'white'])\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# file_id = \"1230105514.master\"\n",
    "# id_to_log = lambda x: \"logs/%s.exp.log\" % x\n",
    "\n",
    "def print_n_flush(*args):\n",
    "#     from __future__ import print_function\n",
    "    import sys\n",
    "    print_on_single_line = False\n",
    "    for arg in args:\n",
    "        if \"\\n\" in arg:\n",
    "            if print_on_single_line:\n",
    "                print \"\\n\"\n",
    "                print_on_single_line = False\n",
    "            for aa in arg.split(\"\\n\"):\n",
    "                print aa\n",
    "        else:\n",
    "            print arg,\n",
    "            print_on_single_line = True\n",
    "    if print_on_single_line:\n",
    "        print \"\"\n",
    "    sys.stdout.flush()\n",
    "    sys.stderr.flush()\n",
    "# filename_log = id_to_log(file_id)\n",
    "# responses, tests, responses_t, tests_t, images = toCSV(filename_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quiver_annotations = []\n",
    "from leaparticulator.data.trajectory import Trajectory\n",
    "def plot_quiver2d(data, alpha=.75, C=[], path=None, *args, **kwargs):\n",
    "    global quiver_annotations\n",
    "    \n",
    "    X, Y = zip(*tuple(data))\n",
    "    U = [x1-x0 for x0,x1 in zip(X[:-1],X[1:])]\n",
    "    V = [y1-y0 for y0,y1 in zip(Y[:-1],Y[1:])]\n",
    "    if C == []:\n",
    "        color_delta = 1. / (len(X) - 1)\n",
    "        C = [(color_delta*i,color_delta*i,color_delta*i) for i in range(len(X)-1)]\n",
    "#     print_n_flush(_n_flush( C))\n",
    "    X, Y = X[:-1], Y[:-1]\n",
    "#     print_n_flush(_n_flush( X, Y, U, V))\n",
    "    patches = quiver(X, Y, U, V, *args, edgecolors=[\"black\" for i in C], scale_units='xy',angles='xy', scale=1, width=0.005, alpha=alpha, **kwargs)\n",
    "    return patches    \n",
    "    \n",
    "def find_bounding_box(trajectories):\n",
    "    xmin = ymin = 1000\n",
    "    xmax = ymax = -1000\n",
    "    delta = 1\n",
    "    for signal in trajectories:\n",
    "        for frame in signal:\n",
    "            x, y, z = frame.get_stabilized_position()\n",
    "            xmax = max(x + delta, xmax)\n",
    "            xmin = min(x - delta, xmin)\n",
    "            ymax = max(y + delta, ymax)\n",
    "            ymin = min(y - delta, ymin)\n",
    "    return xmin, xmax, ymin, ymax\n",
    "\n",
    "def to_trajectory_object(trajectory, xmin, ymin, xmax, ymax, step_size=10):\n",
    "    arr = [frame.get_stabilized_position()[:2] for frame in trajectory]\n",
    "    t = Trajectory(from_arr=arr, duration=len(arr), step_size=step_size, origin=(xmin, ymin), \n",
    "                   ndim=2, dim_size=(xmax-xmin, ymax-ymin), prob_c=1)\n",
    "    return t\n",
    "\n",
    "def to_trajectory_file(trajectories, filename):\n",
    "    xmin, xmax, ymin, ymax = find_bounding_box(trajectories)\n",
    "    start = 0\n",
    "    end = 1\n",
    "    import os\n",
    "    if os.path.isfile(filename):\n",
    "        os.remove(filename)\n",
    "    with open(filename, \"w\") as f:\n",
    "        print_n_flush(_n_flush((xmin, xmax, ymin, ymax, start,end)))\n",
    "        f.write(\"%d %d %d %d %d %d\\n\" % (xmin, xmax, ymin, ymax, start,end))\n",
    "        for signal in trajectories:\n",
    "            for frame in signal:\n",
    "                x, y, z = frame.get_stabilized_position()\n",
    "                time = frame.timestamp\n",
    "                f.write(\"%f %f %f\\n\" % (x, y, time))\n",
    "            f.write(\"0.0 0.0 0.0\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = responses[\"127.0.0.1\"]\n",
    "# r = r['1']\n",
    "# r = {\"1\":r}\n",
    "def responses_to_trajectories(responses):\n",
    "    counter = 0\n",
    "    trajectories = []\n",
    "    for host in responses:\n",
    "        r = responses[host]\n",
    "        for phase in r:\n",
    "            for image in r[phase]:\n",
    "        #         if image == u'./img/meanings/5_1.png':\n",
    "                    counter+=1\n",
    "                    trajectory = r[phase][image]\n",
    "                    trajectories.append(trajectory)\n",
    "                    data = []\n",
    "                    for frame in trajectory[:-1]:\n",
    "                        x, y, z = frame.get_stabilized_position()\n",
    "                        data.append((x,y))\n",
    "        #                 print_n_flush( frame.timestamp)\n",
    "        #             plot_quiver2d(data)\n",
    "        #             break\n",
    "        #             plot(X,Y,label=\"%s-%s\" % (phase, image))\n",
    "    return trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting HMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cov_ellipse(cov, pos, nstd=2, ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots an `nstd` sigma error ellipse based on the specified covariance\n",
    "    matrix (`cov`). Additional keyword arguments are passed on to the \n",
    "    ellipse patch artist.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        cov : The 2x2 covariance matrix to base the ellipse on\n",
    "        pos : The location of the center of the ellipse. Expects a 2-element\n",
    "            sequence of [x0, y0].\n",
    "        nstd : The radius of the ellipse in numbers of standard deviations.\n",
    "            Defaults to 2 standard deviations.\n",
    "        ax : The axis that the ellipse will be plotted on. Defaults to the \n",
    "            current axis.\n",
    "        Additional keyword arguments are pass on to the ellipse patch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A matplotlib ellipse artist\n",
    "    \"\"\"\n",
    "    from matplotlib.pyplot import gca\n",
    "    def eigsorted(cov):\n",
    "        vals, vecs = np.linalg.eigh(np.asarray(cov).reshape((2,2)))\n",
    "        order = vals.argsort()[::-1]\n",
    "        return vals[order], vecs[:,order]\n",
    "\n",
    "    if ax is None:\n",
    "        ax = gca()\n",
    "\n",
    "    vals, vecs = eigsorted(cov)\n",
    "    theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "\n",
    "    # Width and height are \"full\" widths, not radius\n",
    "    width, height = 2 * nstd * np.sqrt(vals)\n",
    "    ellip = Ellipse(xy=pos, width=width, height=height, angle=theta, ec=\"black\", **kwargs)\n",
    "\n",
    "    ax.add_artist(ellip)\n",
    "    return ellip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-095357101942>:54: SyntaxWarning: name 'means' is used prior to global declaration\n",
      "  global means\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import colorConverter\n",
    "from matplotlib.patches import Ellipse, ArrowStyle\n",
    "from matplotlib.pyplot import scatter, annotate, quiver, legend, gca, gcf, draw\n",
    "from numpy import log, exp\n",
    "# figure()\n",
    "means = []\n",
    "annotations = []\n",
    "\n",
    "def on_pick(event):\n",
    "    print_n_flush( str(event))\n",
    "    print_n_flush( str(annotations))\n",
    "    if event.artist in annotations:\n",
    "        on_pick_annotation(event)\n",
    "    elif event.artist in means:\n",
    "        on_pick_means(event)\n",
    "#     draw()\n",
    "#     time.sleep(1)\n",
    "\n",
    "def on_pick_trajectory_event(event):\n",
    "    pass\n",
    "    \n",
    "def on_pick_annotation(event):\n",
    "    print_n_flush( \"Annotation: %s\" % event.artist)\n",
    "    event.artist.set_visible(False)\n",
    "\n",
    "def on_pick_means(event):\n",
    "    print_n_flush( \"Mean: %s\" % means.index(event.artist))\n",
    "    annotations[means.index(event.artist)].set_visible(True)\n",
    "    print_n_flush( \"%s\" % annotations[means.index(event.artist)])\n",
    "    \n",
    "def plot_hmm(means_, transmat, covars, initProbs, axes=None, clr=None, transition_arrows=True,\n",
    "            prob_lists=True):\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib.patches import FancyArrowPatch\n",
    "    univariate = False\n",
    "    try:\n",
    "        iter(means_[0])\n",
    "    except TypeError:\n",
    "        univariate = True\n",
    "        print_n_flush(\"Univariate HMM detected (%d states).\" % len(means_))\n",
    "        print means[:3]\n",
    "        means_ = [(0,m)for m in means_]\n",
    "#         covars = [[[3,0],[0,covar]] for covar in covars]\n",
    "        \n",
    "    if axes != None:\n",
    "        pass\n",
    "#         plt.axes(axes)\n",
    "    else:\n",
    "        axes = plt.gca()\n",
    "#     f, axes = subplots(2)#,sharex=True, sharey=True)\n",
    "#     sca(axes[0])\n",
    "    global annotations\n",
    "    annotations = []\n",
    "    global means\n",
    "    means = []\n",
    "    arrows = []\n",
    "    colors=clr\n",
    "    max_prob = 0\n",
    "    for i, row in enumerate(transmat):\n",
    "        for j, p in enumerate(row):\n",
    "            # ignore self-transitions\n",
    "            if i!= j:\n",
    "                max_prob = max(max_prob, p)\n",
    "    \n",
    "#     max_prob = max(transmat.flatten())\n",
    "    for i, mean in enumerate(means_):\n",
    "        color = colors[i % len(colors)]\n",
    "        print_n_flush( \"MEAN:\", tuple(mean))\n",
    "        means.append(axes.scatter(*tuple(mean), color=color, picker=10, label=\"State%i\"%i))\n",
    "        axes.annotate(s=\"%d\" % i, xy=mean, xytext=(-10,-10), xycoords=\"data\",textcoords=\"offset points\", \n",
    "                         alpha=1,bbox=dict(boxstyle='round,pad=0.2', fc=color, alpha=0.3))\n",
    "        print_n_flush( \"COVARS: %s\" % covars[i])\n",
    "        if not univariate:\n",
    "            plot_cov_ellipse(covars[i], mean, alpha=.30, color=color, ax=axes)\n",
    "        else:\n",
    "            axes.axhspan(mean[1] - np.sqrt(covars[i]),mean[1] + np.sqrt(covars[i]), color=color, alpha=.30)\n",
    "        x0, y0 = mean\n",
    "        prob_string = \"P(t0)=%f\" % initProbs[i]\n",
    "        for j, p in enumerate(transmat[i]):\n",
    "            xdif = 10\n",
    "            ydif = 5\n",
    "            s = \"P(%d->%d)=%f\" % (i,j,p)\n",
    "#             print_n_flush( \"State%d: %s\" % (i, s))\n",
    "            prob_string = \"%s\\n%s\" % (prob_string,s)\n",
    "            if transition_arrows:\n",
    "                if i != j:\n",
    "                    x1, y1 = means_[j]\n",
    "                    # if transmat[i][j] is too low, we get an underflow here\n",
    "    #                 q = quiver([x0], [y0], [x1-x0], [y1-y0], alpha = 10000 * (transmat[i][j]**2),\n",
    "                    alpha = 0\n",
    "                    if p > 10 ** -300:\n",
    "                        alpha = (p*100000) / (max_prob * 100000)\n",
    "                    alpha = min(1.,(exp(2 * alpha / (len(means)*.5))) - 1)\n",
    "                    \n",
    "#                     alpha_in = 0\n",
    "#                     if transmat[j][i] > 10 ** -300:\n",
    "#                         alpha_in = (transmat[j][i]*100000) / (max_prob * 100000)\n",
    "#                     alpha_in = min(1.,(exp(alpha_in / (len(means)*.5))) - 1)\n",
    "                    \n",
    "#                     print alpha, old_alpha, p, max_prob\n",
    "#                     alpha = max(0, 1. / log(alpha))\n",
    "                    width = .55\n",
    "                    color = \"red\"\n",
    "                    if x1 > x0:\n",
    "                        color = \"green\"\n",
    "#                     if j > i:\n",
    "                    c_arrows = FancyArrowPatch(\n",
    "                        (x0, y0),\n",
    "                        (x1, y1),\n",
    "                        connectionstyle='arc3, rad=-.25',\n",
    "                        mutation_scale=10,\n",
    "                        # red is forward, green is backward prob\n",
    "                        color=color,\n",
    "                        alpha=alpha,\n",
    "                        linewidth=width,\n",
    "                        arrowstyle=ArrowStyle.Fancy(head_length=width*4, \n",
    "                                                    head_width=width*2.5, \n",
    "                                                    ))\n",
    "#                     c_arrows = FancyArrow(x0, y0, x1-x0, y1-y0, alpha=alpha, color=\"black\",\n",
    "#                                          width=width, head_width=width * 2.5, head_length=width * 4.,\n",
    "#                                          overhang=1.)\n",
    "#                                             connectionstyle=\"angle3,angleA=0,angleB=-90\")\n",
    "                    axes.add_patch(c_arrows)\n",
    "                    arrows.append(c_arrows)\n",
    "#                     q = axes.quiver([x0], [y0], [x1-x0], [y1-y0], alpha = alpha, \n",
    "#                            scale_units='xy',angles='xy', scale=1, width=0.005, \n",
    "#                             label=\"P(%d->%d)=%f\" % (i,j,p))\n",
    "#         legend()\n",
    "        if prob_lists:\n",
    "            annotations.append(annotate(s=prob_string, xy=mean, xytext=(0, 10), xycoords=\"data\",textcoords=\"offset points\", \n",
    "                         alpha=1,bbox=dict(boxstyle='round,pad=0.2', fc=color, alpha=0.3), picker=True,\n",
    "                         visible=True))\n",
    "\n",
    "\n",
    "#         print_n_flush( \"State%i is %s\" % (i, colors[i]))\n",
    "    cid = gcf().canvas.mpl_connect('pick_event', on_pick)\n",
    "    axes.legend()\n",
    "    print_n_flush(\"Returning from plot_hmm\")\n",
    "    return annotations, means, arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-66fcba78cef3>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-66fcba78cef3>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def plot_hmm_path(trajectory_objs, paths, legends=[], items=[]):\n",
    "    from matplotlib import pyplot as plt\n",
    "    global colors\n",
    "#     print_n_flush( \"Colors are:\", colors)\n",
    "    for i, (trajectory, p) in enumerate(zip(trajectory_objs, paths)): \n",
    "#         print_n_flush( \"Path:\", p)\n",
    "        tr_colors = [colors[int(state)] for state in p]\n",
    "        try:\n",
    "            len(trajectory[0])\n",
    "            t = trajectory.plot2d(color=tr_colors)\n",
    "        except TypeError:\n",
    "            t = trajectory.plot(color=tr_colors)\n",
    "    #     t = plot_quiver2d(trajectory, color=tr_colors, path=p)\n",
    "#         too_high = [tt for tt in trajectory if tt[1] > 400]\n",
    "#         print_n_flush( \"Too high\", too_high)\n",
    "        legends.append(\"Trajectory%i\" % i)\n",
    "    #     items.append(p)\n",
    "        items.append(t)\n",
    "    #gca().legend()\n",
    "\n",
    "\n",
    "\n",
    "    # Let's create checkboxes\n",
    "    rax = plt.axes([0.05, 0.4, 0.1, 0.15])\n",
    "    # rax = plt.gca()\n",
    "    from matplotlib.widgets import CheckButtons\n",
    "    check = CheckButtons(rax, legends, [True] * len(legends))\n",
    "    # plt.sca(axes)\n",
    "\n",
    "    def func(label):\n",
    "        widget = items[legends.index(label)]\n",
    "        widget.set_visible(not widget.get_visible())\n",
    "        plt.draw()\n",
    "\n",
    "    check.on_clicked(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Constants\n",
    "def fn(args):\n",
    "    from leaparticulator.data.hmm import reduce_hmm\n",
    "    from leaparticulator.notebooks.GHmmWrapper import train_hmm_on_set_of_obs\n",
    "#     import dill\n",
    "    from pickle import dumps\n",
    "    data,nstates,range_x,range_y = args\n",
    "    hmm = train_hmm_on_set_of_obs(data,nstates,range_x,range_y)\n",
    "#     print type(hmm)\n",
    "#     return 1\n",
    "    return reduce_hmm(hmm)[1]\n",
    "        \n",
    "def train_hmm_n_times(file_id, nstates, trials=20, iter=1000, pickle=True, \n",
    "                      phase=2, cond=None, units=Constants.XY, parallel=True,\n",
    "                      include_practice=True, multivariate=None):\n",
    "    \"\"\"\n",
    "    Trains multiple HMM's (as many as trials parameter per nstate) and chooses the one with the \n",
    "    lowest BIC, so as to avoid local optima. units parameter can be \"xy\", \"amp_and_freq\", or\n",
    "    \"amp_and_mel\", which specifies the kind of data to fit the HMM to. \n",
    "    \n",
    "    When include_practice=False, data from practice rounds are not used for the training. \n",
    "    \n",
    "    multivariate parameter overrides the multivariate detection.\n",
    "    \"\"\"\n",
    "    def pick_lowest_bic(models):\n",
    "        hmm, d, bic = None, None, 9999999999\n",
    "        if not any(models):\n",
    "            print \"There are no valid models, WTF?!? Returning 'None'...\"\n",
    "            return None\n",
    "        for hmm_ in models:\n",
    "#             hmm_ = HMM(hmm__, training_data=hmm__.obs, hmm_type=\"ghmm\")\n",
    "            if hmm_.bic < bic:\n",
    "                bic = hmm_.bic\n",
    "                hmm = hmm_\n",
    "#             return None\n",
    "#         Hmm = HMM(hmm, training_data=d, hmm_type=\"hmmlearn\")\n",
    "#         print_n_flush( \"New hmm and data (%s)\" % d)\n",
    "#         Hmm.from_R(hmm)\n",
    "        return hmm\n",
    "    \n",
    "    \n",
    "    \n",
    "    import leaparticulator.notebooks.GHmmWrapper\n",
    "#     reload(GHmmWrapper)\n",
    "    from leaparticulator.notebooks.GHmmWrapper import train_hmm_on_set_of_obs, bic, aic, get_range_of_multiple_traj\n",
    "#     reload(ExperimentalData)\n",
    "    from leaparticulator.data.functions import fromFile\n",
    "    from leaparticulator.data.hmm import reduce_hmm, reconstruct_hmm\n",
    "    from leaparticulator.constants import palmToAmpAndFreq,palmToAmpAndMel\n",
    "    \n",
    "    ff = id_to_log(file_id)\n",
    "    print_n_flush(\"Loading log file: %s...\" % ff)\n",
    "    responses, test_results, responses_p, test_p, images = fromFile(ff)\n",
    "    print_n_flush(\"Loaded.\")\n",
    "    multivariate = False\n",
    "    reverse_cond = cond in (\"2r\",\"1r\")\n",
    "    interval = 1\n",
    "    pick_var = 0\n",
    "    if reverse_cond:\n",
    "        interval = -1\n",
    "        pick_var = 1\n",
    "    if multivariate is None:\n",
    "        if cond in (\"2\",\"2r\"):\n",
    "            if phase == 1:\n",
    "                multivariate = True\n",
    "        else:\n",
    "            if phase == 2:\n",
    "                multivariate = True\n",
    "            \n",
    "    formatData = None\n",
    "            \n",
    "    if multivariate:\n",
    "        if units == Constants.XY:\n",
    "            formatData = lambda r, phase: [[frame.get_stabilized_position()[:2][::interval] for frame in rr] for rr in r[\"127.0.0.1\"][str(phase)].values()]\n",
    "        elif units == Constants.AMP_AND_FREQ:\n",
    "            # -interval, because amp_and_freq returns y,x and not x,y. \n",
    "            formatData = lambda r, phase: [[palmToAmpAndFreq(frame.get_stabilized_position())[::-interval] for frame in rr] for rr in r[\"127.0.0.1\"][str(phase)].values()]\n",
    "        elif units == Constants.AMP_AND_MEL:\n",
    "            # -interval, because amp_and_freq returns y,x and not x,y. \n",
    "            formatData = lambda r, phase: [[palmToAmpAndMel(frame.get_stabilized_position())[::-interval] for frame in rr] for rr in r[\"127.0.0.1\"][str(phase)].values()]\n",
    "    else:\n",
    "        if units == Constants.XY:\n",
    "            formatData = lambda r, phase: [[frame.get_stabilized_position()[pick_var] for frame in rr] for rr in r[\"127.0.0.1\"][str(phase)].values()]\n",
    "        elif units == Constants.AMP_AND_FREQ:\n",
    "            # -interval, because amp_and_freq returns y,x and not x,y. \n",
    "            formatData = lambda r, phase: [[palmToAmpAndFreq(frame.get_stabilized_position())[::-interval][pick_var] for frame in rr] for rr in r[\"127.0.0.1\"][str(phase)].values()]\n",
    "        elif units == Constants.AMP_AND_MEL:\n",
    "            # -interval, because amp_and_freq returns y,x and not x,y. \n",
    "            formatData = lambda r, phase: [[palmToAmpAndMel(frame.get_stabilized_position())[::-interval][pick_var] for frame in rr] for rr in r[\"127.0.0.1\"][str(phase)].values()]\n",
    "    \n",
    "    data = formatData(responses,phase)\n",
    "    if include_practice: \n",
    "        data += formatData(responses_p,phase)\n",
    "    print_n_flush(\"Sample data: %s\" % data[0][:3])\n",
    "#     data = [[frame.get_stabilized_position()[:2] for frame in response] for response in data]\n",
    "#     data.append()\n",
    "    lview=client=None\n",
    "    if parallel:\n",
    "        from IPython.parallel import Client\n",
    "        client = Client(profile=\"default\")\n",
    "        from types import FunctionType\n",
    "        from IPython.utils.pickleutil import can_map\n",
    "\n",
    "        can_map.pop(FunctionType, None)\n",
    "        import dill, pickle\n",
    "        from IPython.kernel.zmq import serialize\n",
    "        serialize.pickle = pickle\n",
    "\n",
    "        client[:].use_dill()\n",
    "        reg =\"import copy_reg;import leaparticulator.data.hmm;copy_reg.constructor(leaparticulator.data.hmm.reconstruct_hmm);copy_reg.pickle(leaparticulator.data.hmm.HMM, leaparticulator.data.hmm.reduce_hmm, leaparticulator.data.hmm.reconstruct_hmm)\"\n",
    "    #     print type(data), type(data[0])\n",
    "\n",
    "        client[:].execute(reg)\n",
    "        #     print data \n",
    "\n",
    "        lview = client.load_balanced_view() # default load-balanced \n",
    "\n",
    "        lview.block = True\n",
    "    to_return = []\n",
    "    range_x, range_y=get_range_of_multiple_traj(data)\n",
    "    \n",
    "    for n in nstates:\n",
    "        print_n_flush(\"Doing %d state models...\" % n) \n",
    "        args = [(data,n,range_x,range_y)] * trials\n",
    "        \n",
    "        if not parallel:    \n",
    "            hmms = map(fn,args)#[(data,nstates,range_x,range_y)] * trials)\n",
    "        else:\n",
    "            hmms = lview.map(fn,args)#[(data,nstates,range_x,range_y)] * trials)\n",
    "        hmms = [reconstruct_hmm(matrix, data) for matrix,data in hmms]\n",
    "        \n",
    "        to_return.append(pick_lowest_bic(hmms))\n",
    "\n",
    "    if pickle:\n",
    "        print_n_flush(\"Moving on to the pickling of results...\")\n",
    "        pickle_results(to_return, nstates, trials, iter, id_to_log(file_id), phase, units=units)\n",
    "    return to_return\n",
    "        \n",
    "def pickle_results(results, nstates, trials, iter, filename_log, phase=None, units=Constants.XY):\n",
    "    from leaparticulator.data import hmm as hmm_module\n",
    "    hmms, ds = [], []\n",
    "    for hmm in results:\n",
    "        if hmm is None:\n",
    "            hmms.append(hmm)\n",
    "            ds.append(None)\n",
    "        else:\n",
    "            hmm, d = hmm_module.reduce_hmm(hmm)[1]\n",
    "            hmms.append(hmm)\n",
    "            ds.append(d)\n",
    "        \n",
    "    hmms, ds = zip(*[hmm_module.reduce_hmm(hmm)[1] for hmm in results])\n",
    "    assert any(hmms)\n",
    "    assert any(ds)\n",
    "#     print_n_flush(hmms)\n",
    "#     results_pickled = jsonpickle.encode((hmms, ds, nstates, trials, iter))\n",
    "    extension = \".hmms\"\n",
    "    if (phase is not None):\n",
    "        extension = \".phase%d.%s.hmms\" % (phase, units)\n",
    "    print_n_flush( \"Writing results to %s\" % (filename_log + extension) )\n",
    "    with open(filename_log + extension, \"w\") as f:\n",
    "        for i, item in zip((\"hmms\", \"ds\", \"nstates\", \"trials\", \"iter\"),(hmms, ds, nstates, trials, iter)):\n",
    "            print_n_flush( i)\n",
    "#                 for a, hmm in enumerate(item):\n",
    "#                     print_n_flush( a, \"********\\n\", str(hmm))\n",
    "# #                     import pickle\n",
    "# #                     pickle.dumps(hmm)\n",
    "# #                     encoded = jsonpickle.encode(hmm)\n",
    "# #                     jsonpickle.decode(encoded)\n",
    "#                 f.write(jsonpickle.encode(item))\n",
    "#             else:\n",
    "#             print_n_flush( item)\n",
    "            f.write(jsonpickle.encode(item))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "def unpickle_results(filename_log, phase=None, units=None):\n",
    "    \"\"\"\n",
    "    Unpickles .hmms JSON files, given the name of the exp.log file, the\n",
    "    phase this hmm belongs to (given by the .hmms file's name as in \n",
    "    blahblah.exp.log.phase0.amp_and_freq.hmms). Returns a named tuple \n",
    "    of hmms, paths, number of states, trial and iteration numbers. If \n",
    "    given an .hmms file, phase and units parameters are overridden by \n",
    "    the filename.\"\"\"\n",
    "    from leaparticulator.data import hmm as hmm_module\n",
    "    from collections import namedtuple\n",
    "    extension = \".hmms\"\n",
    "    hmms = ds = nstates = trials = iter = None\n",
    "    if filename_log.split('.')[-1] != 'hmms':\n",
    "        print filename_log\n",
    "        assert phase and units\n",
    "        extension = \".phase%d.%s.hmms\" % (phase, units)\n",
    "        # this clause is purely for backward compatibility with\n",
    "        # old pickle files\n",
    "#         else:\n",
    "#             extension = \".phase%d.hmms\" % (phase)\n",
    "        filename_log = filename_log + extension\n",
    "#     else:\n",
    "#         try:\n",
    "#             assert filename_log.split('.')[-1] == \"hmms\"\n",
    "#         except:\n",
    "#             print filename_log, \"is an invalid hmms file.\"\n",
    "#             raise Exception()\n",
    "    \n",
    "#     print \"Unpickle %s\" % (filename_log)        \n",
    "    with open(filename_log, \"r\") as f:\n",
    "        hmms =  jsonpickle.decode(f.readline().rstrip())\n",
    "        ds =  jsonpickle.decode(f.readline().rstrip())\n",
    "#         print \"D's: \\n\", ds\n",
    "        hmms = [hmm_module.reconstruct_hmm(hmm, d) for hmm,d in zip(hmms,ds)]\n",
    "        nstates =  jsonpickle.decode(f.readline().rstrip())\n",
    "        trials =  jsonpickle.decode(f.readline().rstrip())\n",
    "        iter =  jsonpickle.decode(f.readline().rstrip())\n",
    "    Results = namedtuple(\"Results\", \"hmms ds nstates trials iterations\")\n",
    "    return Results(hmms, ds, nstates, trials, iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def responses_to_traj_objs(responses, responses_t=None, to_file=False):\n",
    "    import trajectory\n",
    "    # reload(trajectory)\n",
    "    trajectories = responses_to_trajectories(responses)\n",
    "    if responses_t:\n",
    "        trajectories_t = responses_to_trajectories(responses_t)\n",
    "    else:\n",
    "        trajectories_t = []\n",
    "    if to_file:\n",
    "        to_trajectory_file(trajectories, \"%s.trajectories\" % (\".\".join(filename_log.split(\".\")[:-2])))\n",
    "\n",
    "    all_trajectories = list(trajectories)\n",
    "    all_trajectories.extend(trajectories_t)\n",
    "    xmin, xmax, ymin, ymax = find_bounding_box(trajectories)\n",
    "    tr = [to_trajectory_object(trajectory, step_size=300, xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax) for trajectory in all_trajectories]\n",
    "    return tr, trajectories\n",
    "\n",
    "def pick_hmm_by_bic(hmms, responses, responses_t, plot=True):\n",
    "    responses_to_traj_objs(responses, responses_t)\n",
    "    states, bics, aics = [], [], []\n",
    "    best = 0\n",
    "    tr, trajectories = responses_to_traj_objs(responses, responses_t)\n",
    "    for i, (hmm, d) in enumerate(results):\n",
    "        if hmm is not None:\n",
    "    #         nstates = hmm[0][2][1][0]\n",
    "    #         bic = hmm[2][0]\n",
    "    #         aic = hmm[3][0]\n",
    "    #         nstates = hmm.rx(\"HMM\")[0].rx('distribution')[0].rx('nStates')[0]\n",
    "    #         bic = hmm.rx(\"BIC\")[0][0]\n",
    "    #         aic = hmm.rx(\"AIC\")[0][0]\n",
    "            states.append(hmm.nstates)\n",
    "            bics.append(hmm.bic)\n",
    "            if min(bics) == hmm.bic:\n",
    "                best = i\n",
    "            aics.append(hmm.aic)\n",
    "            #print_n_flush( aic, bic, nstates)\n",
    "#     print_n_flush( states)\n",
    "    n = sum(map(len, trajectories))\n",
    "    # n = len(trajectories)\n",
    "    # aicc = [aic + 2*k*(k+1)/(n-k-1) for aic, k in zip(aics, [s + s + s*s + s + s*2 for s in states])]\n",
    "    # plot nStates against BIC\n",
    "    if plot:\n",
    "        scatter(states, bics, label=\"BIC\", color=\"r\")\n",
    "        scatter(states, aics, label=\"AIC\", color='g')\n",
    "        # scatter(states, aicc, label=\"AICc\", color='b')\n",
    "        legend()\n",
    "    hmm, d = results[best]\n",
    "#     print_n_flush( best)\n",
    "#     print_n_flush( aics)\n",
    "    return hmm, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_log_file(file_id, nstates, trials, iter):\n",
    "#     id_to_log = lambda x: \"logs/%s.exp.log\" % x\n",
    "    filename_log = id_to_log(file_id)\n",
    "    responses, tests, responses_t, tests_t, images = toCSV(filename_log)\n",
    "    \n",
    "    from IPython.parallel import Client\n",
    "#     from functools import partial\n",
    "    from rpy2.rinterface import initr\n",
    "    try:\n",
    "        rinterface.set_initoptions((\"--max-ppsize=500000\"))\n",
    "    except RuntimeError, e:\n",
    "        print_n_flush( \"Runtime error, probably redundant call to set_initoptions()\")\n",
    "        print_n_flush( e)\n",
    "    initr()\n",
    "    client = Client(profile=\"default\")\n",
    "    # client[:].push(dict(initr=initr))\n",
    "    # client[:].apply_sync(lambda: initr())\n",
    "    lview = client.load_balanced_view() # default load-balanced view\n",
    "    lview.block = True\n",
    "    # func = lambda args: train_hmm_n_times(file_id=args[0], nstates=args[1], trials=args[2], iter=args[3])\n",
    "    # trials = 4\n",
    "    client[:].push(dict(train_hmm_once=train_hmm_once))\n",
    "    # args = [(file_id, nstates, trials, 1000) for nstates in range(5,10)]\n",
    "    # results = lview.map(func, args)# hmm, d, results = train_hmm_n_times(file_id, nstates, trials=20, iter=1000)\n",
    "    # pool.join()\n",
    "    results = train_hmm_n_times(file_id, nstates=nstates, trials=trials, iter=iter)\n",
    "    return results\n",
    "\n",
    "def analyze_log_file_in_phases(file_id, nstates, trials, iter):\n",
    "    print_n_flush( \"Starting phase by phase analysis...\")\n",
    "#     id_to_log = lambda x: \"logs/%s.exp.log\" % x\n",
    "    filename_log = id_to_log(file_id)\n",
    "    responses, tests, responses_t, tests_t, images = toCSV(filename_log)\n",
    "    from IPython.parallel import Client\n",
    "#     from functools import partial\n",
    "    from rpy2.rinterface import initr\n",
    "    rinterface.set_initoptions((\"--max-ppsize=100000\"))\n",
    "    initr()\n",
    "    client = Client(profile=\"default\")\n",
    "    # client[:].push(dict(initr=initr))\n",
    "    # client[:].apply_sync(lambda: initr())\n",
    "    lview = client.load_balanced_view() # default load-balanced view\n",
    "    lview.block = True\n",
    "    # func = lambda args: train_hmm_n_times(file_id=args[0], nstates=args[1], trials=args[2], iter=args[3])\n",
    "    # trials = 4\n",
    "    client[:].push(dict(train_hmm_once=train_hmm_once))\n",
    "    # args = [(file_id, nstates, trials, 1000) for nstates in range(5,10)]\n",
    "    # results = lview.map(func, args)# hmm, d, results = train_hmm_n_times(file_id, nstates, trials=20, iter=1000)\n",
    "    # pool.join()\n",
    "    results = {}\n",
    "    for i in range(3):\n",
    "        results[i] = train_hmm_n_times(file_id, nstates=nstates, trials=trials, iter=iter, phase=i)\n",
    "    return results\n",
    "\n",
    "def analyze_log_file_in_phases_by_condition(file_id, nstates, trials, iter, units=Constants.XY, parallel=True, \n",
    "                                            prefix=\"logs/\", skip_phases=[], include_practice=True,\n",
    "                                           multivariate=None):\n",
    "    \"\"\"\n",
    "    file_id: the id of the participant in the form 14701883.cond\n",
    "    nstates: a list of integers that signify the potential number of states for the HMMs\n",
    "    trials: number of attempts to build an HMM per phase and nstate.\n",
    "    iter: number of iterations (RHmm only)\n",
    "    units: the unit of measurement such as constants.XY, constants.AMP_AND_FREQ etc.\n",
    "    parallel: whether to use parallel processing\n",
    "    prefix: the prefix of the log directory relative to the project root\n",
    "    skip_phases: a list of phases to skip, used to limit memory usage\n",
    "    include_practice: whether practice rounds will be included in the trainign\n",
    "    multivariate: overrides the multi-/univariate choices based on condition and phase, unless set to None.\n",
    "    \"\"\"\n",
    "    \n",
    "    import gc, os\n",
    "    print_n_flush( \"Starting phase by phase analysis, controlled for conditions (units: %s)...\" % units)\n",
    "#     d = pd.read_csv(\"/shared/AudioData/ThereminData/surfacedata.csv\", na_values=[\"NaN\"])\n",
    "    global id_to_log\n",
    "    id_to_log = lambda x: os.path.join(os.getcwd(), prefix, \"%s.exp.log\" % x)#\"%s/%s.exp.log\" % (prefix, x)\n",
    "    filename_log = id_to_log(file_id)\n",
    "    cond = file_id.split('.')[-1]\n",
    "    print_n_flush(\"Working dir: %s\" % os.getcwd())\n",
    "    print_n_flush( \"Condition\", cond)\n",
    "    if multivariate is not None:\n",
    "        print_n_flush(\"Multivariate parameter overridden to: %s\" % multivariate)\n",
    "#     print_n_flush(\"Loading file %s...\" % filename_log)\n",
    "#     responses, tests, responses_t, tests_t, images = toCSV(filename_log)\n",
    "#     print print_n_flush(\"Loaded.\")\n",
    "    from IPython.parallel import Client\n",
    "    \n",
    "#     client = Client(profile=\"default\")\n",
    "    # client[:].push(dict(initr=initr))\n",
    "    # client[:].apply_sync(lambda: initr())\n",
    "#     lview = client.load_balanced_view() # default load-balanced view\n",
    "#     lview.block = True\n",
    "    # func = lambda args: train_hmm_n_times(file_id=args[0], nstates=args[1], trials=args[2], iter=args[3])\n",
    "    # trials = 4\n",
    "#     client[:].push(dict(train_hmm_once=train_hmm_once))\n",
    "    # args = [(file_id, nstates, trials, 1000) for nstates in range(5,10)]\n",
    "    # results = lview.map(func, args)# hmm, d, results = train_hmm_n_times(file_id, nstates, trials=20, iter=1000)\n",
    "    # pool.join()\n",
    "    results = {}\n",
    "    for i in range(3):\n",
    "        if str(i) in skip_phases:\n",
    "            print_n_flush(\"Skipping phase#%d\" % i)\n",
    "            continue\n",
    "        print_n_flush(\"Doing phase#%d\" % i)\n",
    "        results[i] = train_hmm_n_times(file_id, nstates=nstates, trials=trials, iter=iter, phase=i, cond=cond,\n",
    "                                       units=units, parallel=parallel, pickle=True, \n",
    "                                       include_practice=include_practice, multivariate=multivariate)\n",
    "        gc.collect()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_hmm_paths(d):\n",
    "    globalenv['d'] = d\n",
    "    r('library(\"RHmm\")')\n",
    "    r('path = list()')\n",
    "    r('for(trajectory in d){ path = c(path, viterbi(hmm, trajectory))}')\n",
    "    path = globalenv['path']\n",
    "    return path\n",
    "# from glob import glob\n",
    "# files = glob(\"logs/*.*.exp.log\")\n",
    "# files = [file for file in files if file[:-8].split(\".\")[-1] in ('master','1','1r','2','2r')]\n",
    "# print_n_flush( files, len(files))\n",
    "# for f in files:\n",
    "#     analyze_log_file_in_phases_by_condition(f[5:-8], 5, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line = 'hmms = analyze_log_file_in_phases_by_condition(\"1320116514.2\", nstates=range(2,30), trials=5, iter=100, parallel=True, units=Constants.XY)'\n",
    "# %lprun -f analyze_log_file_in_phases_by_condition analyze_log_file_in_phases_by_condition(\"1320116514.2\", nstates=range(2,30), trials=5, iter=100, parallel=True, units=Constants.XY)\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    os.chdir(os.path.expanduser(\"~/Dropbox/ABACUS/Workspace/LeapArticulatorQt\"))\n",
    "    hmms_f = analyze_log_file_in_phases_by_condition(\"OS1.1\", prefix=\"logs/logs/orange_squares\", nstates=[10], trials=50, iter=100, parallel=False, units=Constants.AMP_AND_FREQ)\n",
    "# hmms_m = analyze_log_file_in_phases_by_condition(\"1320116514.2\", nstates=10, trials=50, iter=100, parallel=False, units=Constants.AMP_AND_MEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rpy2.robjects.numpy2ri\n",
    "# from rpy2.robjects import r, globalenv\n",
    "\n",
    "# results = analyze_log_file(file_id, nstates = range(10,22), trials = 20, iter = 1000)\n",
    "# hmm, d = pick_hmm_by_bic(results, responses, responses_t, plot=False)\n",
    "\n",
    "# path = pull_hmm_paths(d)\n",
    "\n",
    "# paths = [numpy.asarray(path[i], dtype=int) for i in range(0, len(path), 3)]\n",
    "# tr, trajectories = responses_to_traj_objs(responses,responses_t)\n",
    "\n",
    "def draw():\n",
    "    means = hmm.means\n",
    "    transmat = hmm.transmat\n",
    "    initProb = hmm.initProb\n",
    "    covar = hmm.variances\n",
    "    nstates = hmm.nstates\n",
    "    x = zip(*means)[0]\n",
    "    y = zip(*means)[1]\n",
    "\n",
    "    legends = []\n",
    "    items = []\n",
    "    ax = None\n",
    "\n",
    "    plot_hmm(numpy.asarray(means), \n",
    "            numpy.asarray(transmat),\n",
    "            initProbs=numpy.asarray(initProb),\n",
    "            covars=covar, axes=ax)\n",
    "\n",
    "    plot_hmm_path(paths=paths, \n",
    "                  trajectory_objs=tr, \n",
    "                  legends=legends, \n",
    "                  items=items)\n",
    "    plt.draw()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}